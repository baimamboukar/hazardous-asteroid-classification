{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11244462,
          "sourceType": "datasetVersion",
          "datasetId": 689444
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3e4ff47e4214bd3aaabd375f1576352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebcce68e89604c6090e5920155dc758e"
            ],
            "layout": "IPY_MODEL_442508f460c54cd6b1cd7c80815a2b46"
          }
        },
        "7c6cb994fdb349f79750b66af1ef9298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f13c481c010434cb8aaba72eb68daa7",
            "placeholder": "​",
            "style": "IPY_MODEL_e881825462ca4c39abea6d8f562abf60",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "3851d045e56c4a1dab7421c0f765d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3527be4fbc1f4ef28a698610d95e8114",
            "placeholder": "​",
            "style": "IPY_MODEL_96a4d2005bdc4ccfa7440db2ac9dfa55",
            "value": "baimamboukar"
          }
        },
        "dfbbf57830924938983e2ba0890bfc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_fa0866329bbe4fa7a78018a4fc7ce6a6",
            "placeholder": "​",
            "style": "IPY_MODEL_993a71413ebe47e5a4c76ac8e99bb64f",
            "value": ""
          }
        },
        "1b8ca44f4bad48829d3ceb14d8fc0dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c699013c2cb946e59f655722c88503aa",
            "style": "IPY_MODEL_f2adbd8a2b4943a984439b03ecf834c1",
            "tooltip": ""
          }
        },
        "aaf421b983cd4f9a807057a9c27a642c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6c451d261b4d87a8489984621c6b07",
            "placeholder": "​",
            "style": "IPY_MODEL_2d88565ea46d4b52bfd73ddf8216575d",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "442508f460c54cd6b1cd7c80815a2b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3f13c481c010434cb8aaba72eb68daa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e881825462ca4c39abea6d8f562abf60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3527be4fbc1f4ef28a698610d95e8114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a4d2005bdc4ccfa7440db2ac9dfa55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa0866329bbe4fa7a78018a4fc7ce6a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993a71413ebe47e5a4c76ac8e99bb64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c699013c2cb946e59f655722c88503aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2adbd8a2b4943a984439b03ecf834c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ce6c451d261b4d87a8489984621c6b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d88565ea46d4b52bfd73ddf8216575d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c945e18248ed4fb49a58d1fd466bb658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44126f972e7545f2b99ddba6296c3f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd2c01047ab4e89b03f0524db83e778",
            "value": "Connecting..."
          }
        },
        "44126f972e7545f2b99ddba6296c3f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd2c01047ab4e89b03f0524db83e778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebcce68e89604c6090e5920155dc758e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f651427b7bf74264af414b8bf0bebd26",
            "placeholder": "​",
            "style": "IPY_MODEL_68d324cadef34df3bb1df1db24f76000",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "f651427b7bf74264af414b8bf0bebd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d324cadef34df3bb1df1db24f76000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e3e4ff47e4214bd3aaabd375f1576352",
            "7c6cb994fdb349f79750b66af1ef9298",
            "3851d045e56c4a1dab7421c0f765d87a",
            "dfbbf57830924938983e2ba0890bfc29",
            "1b8ca44f4bad48829d3ceb14d8fc0dc5",
            "aaf421b983cd4f9a807057a9c27a642c",
            "442508f460c54cd6b1cd7c80815a2b46",
            "3f13c481c010434cb8aaba72eb68daa7",
            "e881825462ca4c39abea6d8f562abf60",
            "3527be4fbc1f4ef28a698610d95e8114",
            "96a4d2005bdc4ccfa7440db2ac9dfa55",
            "fa0866329bbe4fa7a78018a4fc7ce6a6",
            "993a71413ebe47e5a4c76ac8e99bb64f",
            "c699013c2cb946e59f655722c88503aa",
            "f2adbd8a2b4943a984439b03ecf834c1",
            "ce6c451d261b4d87a8489984621c6b07",
            "2d88565ea46d4b52bfd73ddf8216575d",
            "c945e18248ed4fb49a58d1fd466bb658",
            "44126f972e7545f2b99ddba6296c3f9f",
            "ddd2c01047ab4e89b03f0524db83e778",
            "ebcce68e89604c6090e5920155dc758e",
            "f651427b7bf74264af414b8bf0bebd26",
            "68d324cadef34df3bb1df1db24f76000"
          ]
        },
        "id": "bASGwJgs5oPK",
        "outputId": "2f1b7720-a3b4-4462-a536-af140924d9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3e4ff47e4214bd3aaabd375f1576352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "sakhawat18_asteroid_dataset_path = kagglehub.dataset_download('sakhawat18/asteroid-dataset')"
      ],
      "metadata": {
        "id": "Tk05xhMux_4r"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sakhawat18_asteroid_dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d7uMhs106ROc",
        "outputId": "64f91e2a-10b9-4b81-9211-2bcf7494f31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/asteroid-dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric -q"
      ],
      "metadata": {
        "id": "x9zyJEw810Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "P1z2K0mnx_40"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "        F_loss = alpha_t * (1 - pt) ** self.gamma * BCE_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "class AsteroidGraphDataset:\n",
        "    def __init__(self, filepath):\n",
        "        logger.info(f\"Loading dataset from {filepath}\")\n",
        "        self.df = pd.read_csv(filepath, low_memory=False)\n",
        "        self.df = self.df.dropna(subset=['pha'])\n",
        "        logger.info(f\"After dropping rows with missing 'pha', dataset size: {len(self.df)}\")\n",
        "\n",
        "        features = ['e', 'a', 'i', 'q', 'tp', 'H', 'diameter', 'albedo', 'moid_ld']\n",
        "        X = self.df[features].astype(float).values\n",
        "        y = (self.df['pha'] == 'Y').astype(int).values\n",
        "\n",
        "        indices = np.arange(len(self.df))\n",
        "        train_val_indices, test_indices = train_test_split(\n",
        "            indices, test_size=0.2, stratify=y, random_state=42\n",
        "        )\n",
        "        train_indices, val_indices = train_test_split(\n",
        "            train_val_indices, test_size=0.2, stratify=y[train_val_indices], random_state=42\n",
        "        )\n",
        "\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        imputer.fit(X[train_indices])\n",
        "        X_imputed = imputer.transform(X)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_imputed[train_indices])\n",
        "        X_scaled = scaler.transform(X_imputed)\n",
        "\n",
        "        train_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        val_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        test_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        train_mask[train_indices] = True\n",
        "        val_mask[val_indices] = True\n",
        "        test_mask[test_indices] = True\n",
        "\n",
        "        connectivity = kneighbors_graph(X_scaled, n_neighbors=5, mode='connectivity')\n",
        "        rows, cols = connectivity.nonzero()\n",
        "        edge_index_np = np.vstack((rows, cols))\n",
        "        edge_index = torch.from_numpy(edge_index_np).to(torch.long)\n",
        "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
        "\n",
        "        self.data = Data(x=torch.tensor(X_scaled, dtype=torch.float),\n",
        "                         edge_index=edge_index,\n",
        "                         y=torch.tensor(y, dtype=torch.float),\n",
        "                         train_mask=train_mask,\n",
        "                         val_mask=val_mask,\n",
        "                         test_mask=test_mask)\n",
        "\n",
        "        logger.info(f\"Graph constructed with {self.data.num_nodes} nodes and {self.data.num_edges} edges\")\n",
        "\n",
        "class AsteroidGNN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(AsteroidGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 128)\n",
        "        self.conv2 = GCNConv(128, 128)\n",
        "        self.conv3 = GCNConv(128, 128)\n",
        "        self.attn = GATConv(128, 64, heads=2)\n",
        "        self.fc = nn.Linear(64 * 2, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = F.relu(self.attn(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "class AsteroidHazardClassifier:\n",
        "    def __init__(self, dataset_path):\n",
        "        logger.info(\"Initializing Asteroid Hazard Classifier\")\n",
        "        self.dataset = AsteroidGraphDataset(dataset_path)\n",
        "        self.model = AsteroidGNN(num_features=len(['e', 'a', 'i', 'q', 'tp', 'H', 'diameter', 'albedo', 'moid_ld']))\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "        self.criterion = FocalLoss(alpha=0.75, gamma=2)\n",
        "\n",
        "    def train(self, epochs=100, patience=10):\n",
        "        logger.info(f\"Starting training for {epochs} epochs\")\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        best_model_state = None\n",
        "\n",
        "        epoch_progress = tqdm(range(epochs), desc=\"Training Epochs\", position=0)\n",
        "\n",
        "        for epoch in epoch_progress:\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(self.dataset.data)\n",
        "            loss = self.criterion(output[self.dataset.data.train_mask], self.dataset.data.y[self.dataset.data.train_mask])\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_output = self.model(self.dataset.data)\n",
        "                val_loss = self.criterion(val_output[self.dataset.data.val_mask], self.dataset.data.y[self.dataset.data.val_mask])\n",
        "\n",
        "            epoch_progress.set_postfix({'Loss': f'{loss.item():.4f}', 'Val Loss': f'{val_loss.item():.4f}'})\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                best_model_state = self.model.state_dict()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    logger.info(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "        self.model.load_state_dict(best_model_state)\n",
        "        logger.info(\"Training completed\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        logger.info(\"Starting model evaluation\")\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = self.model(self.dataset.data)\n",
        "            val_output = output[self.dataset.data.val_mask].cpu().numpy()\n",
        "            val_y = self.dataset.data.y[self.dataset.data.val_mask].cpu().numpy()\n",
        "\n",
        "            precision, recall, thresholds = precision_recall_curve(val_y, val_output)\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "            optimal_idx = np.argmax(f1_scores)\n",
        "            optimal_threshold = thresholds[optimal_idx]\n",
        "            logger.info(f\"Optimal threshold: {optimal_threshold}\")\n",
        "\n",
        "            test_output = output[self.dataset.data.test_mask].cpu().numpy()\n",
        "            test_y = self.dataset.data.y[self.dataset.data.test_mask].cpu().numpy()\n",
        "            test_pred = (test_output > optimal_threshold).astype(int)\n",
        "\n",
        "            logger.info(\"Classification Report:\")\n",
        "            print(classification_report(test_y, test_pred))\n",
        "\n",
        "            cm = confusion_matrix(test_y, test_pred)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "            plt.title('Confusion Matrix', fontsize=10)\n",
        "            plt.xlabel('Predicted', fontsize=10)\n",
        "            plt.ylabel('Actual', fontsize=10)\n",
        "            plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('confusion_matrix.png')\n",
        "            plt.close()\n",
        "            logger.info(\"Confusion matrix saved to confusion_matrix.png\")\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(test_y, test_output)\n",
        "            roc_auc = roc_auc_score(test_y, test_output)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.plot(fpr, tpr, color='dodgerblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "            plt.plot([0, 1], [0, 1], color='crimson', lw=2, linestyle='--')\n",
        "            plt.xlabel('False Positive Rate', fontsize=10)\n",
        "            plt.ylabel('True Positive Rate', fontsize=10)\n",
        "            plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=10)\n",
        "            plt.legend(loc=\"lower right\", fontsize=10)\n",
        "            plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('roc_curve.png')\n",
        "            plt.close()\n",
        "            logger.info(\"ROC curve saved to roc_curve.png\")\n",
        "\n",
        "def main():\n",
        "    # Set the path to the dataset directory\n",
        "    #sakhawat18_asteroid_dataset_path = '/path/to/dataset'  # Replace with actual path\n",
        "    dataset_path = f\"{sakhawat18_asteroid_dataset_path}/dataset.csv\"\n",
        "    classifier = AsteroidHazardClassifier(dataset_path)\n",
        "    classifier.train(epochs=100, patience=10)\n",
        "    classifier.evaluate()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h36QIqHJhoLQ",
        "outputId": "5eb9d1df-b465-4fa3-ddcb-d576cbac28c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epochs: 100%|██████████| 100/100 [44:18<00:00, 26.59s/it, Loss=0.0010, Val Loss=0.0010]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    187308\n",
            "         1.0       0.25      0.54      0.34       413\n",
            "\n",
            "    accuracy                           1.00    187721\n",
            "   macro avg       0.62      0.77      0.67    187721\n",
            "weighted avg       1.00      1.00      1.00    187721\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate -q"
      ],
      "metadata": {
        "id": "i5h-nYGMsM64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from tabulate import tabulate\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'epochs': 100,\n",
        "    'patience': 10,\n",
        "    'save_dpi': 300,\n",
        "    'display_dpi': 120\n",
        "}\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "        F_loss = alpha_t * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return torch.mean(F_loss) if self.reduction == 'mean' else F_loss\n",
        "\n",
        "class AsteroidGraphDataset:\n",
        "    def __init__(self, filepath):\n",
        "        logger.info(f\"Loading dataset from {filepath}\")\n",
        "        self.df = pd.read_csv(filepath, low_memory=False)\n",
        "        self.df = self.df.dropna(subset=['pha'])\n",
        "        logger.info(f\"After dropping rows with missing 'pha', dataset size: {len(self.df)}\")\n",
        "\n",
        "        features = ['e', 'a', 'i', 'q', 'tp', 'H', 'diameter', 'albedo', 'moid_ld']\n",
        "        X = self.df[features].astype(float).values\n",
        "        y = (self.df['pha'] == 'Y').astype(int).values\n",
        "\n",
        "        indices = np.arange(len(self.df))\n",
        "        train_val_indices, test_indices = train_test_split(\n",
        "            indices, test_size=0.2, stratify=y, random_state=42\n",
        "        )\n",
        "        train_indices, val_indices = train_test_split(\n",
        "            train_val_indices, test_size=0.2, stratify=y[train_val_indices], random_state=42\n",
        "        )\n",
        "\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        imputer.fit(X[train_indices])\n",
        "        X_imputed = imputer.transform(X)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_imputed[train_indices])\n",
        "        X_scaled = scaler.transform(X_imputed)\n",
        "\n",
        "        train_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        val_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        test_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        train_mask[train_indices] = True\n",
        "        val_mask[val_indices] = True\n",
        "        test_mask[test_indices] = True\n",
        "\n",
        "        connectivity = kneighbors_graph(X_scaled, n_neighbors=5, mode='connectivity')\n",
        "        rows, cols = connectivity.nonzero()\n",
        "        edge_index_np = np.vstack((rows, cols))\n",
        "        edge_index = torch.from_numpy(edge_index_np).to(torch.long)\n",
        "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
        "\n",
        "        self.data = Data(x=torch.tensor(X_scaled, dtype=torch.float),\n",
        "                         edge_index=edge_index,\n",
        "                         y=torch.tensor(y, dtype=torch.float),\n",
        "                         train_mask=train_mask,\n",
        "                         val_mask=val_mask,\n",
        "                         test_mask=test_mask)\n",
        "\n",
        "        logger.info(f\"Graph constructed with {self.data.num_nodes} nodes and {self.data.num_edges} edges\")\n",
        "\n",
        "class AsteroidGNN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(AsteroidGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 128)\n",
        "        self.conv2 = GCNConv(128, 128)\n",
        "        self.conv3 = GCNConv(128, 128)\n",
        "        self.attn = GATConv(128, 64, heads=2)\n",
        "        self.fc = nn.Linear(64 * 2, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = F.relu(self.attn(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "class GATModel(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(GATModel, self).__init__()\n",
        "        self.gat1 = GATConv(num_features, 64, heads=2)\n",
        "        self.gat2 = GATConv(64 * 2, 64, heads=2)\n",
        "        self.fc = nn.Linear(64 * 2, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.gat1(x, edge_index))\n",
        "        x = F.relu(self.gat2(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "class AsteroidHazardClassifier:\n",
        "    def __init__(self, dataset_path, model_type='GNN'):\n",
        "        logger.info(f\"Initializing {model_type} Classifier\")\n",
        "        self.dataset = AsteroidGraphDataset(dataset_path)\n",
        "        self.model_type = model_type\n",
        "        num_features = self.dataset.data.x.shape[1]\n",
        "        self.model = AsteroidGNN(num_features) if model_type == 'GNN' else GATModel(num_features)\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "        self.criterion = FocalLoss(alpha=0.75, gamma=2)\n",
        "\n",
        "    def train(self, epochs=config['epochs'], patience=config['patience']):\n",
        "        logger.info(f\"Starting {self.model_type} training for {epochs} epochs\")\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        best_model_state = None\n",
        "        history = []\n",
        "\n",
        "        epoch_progress = tqdm(range(1, epochs + 1), desc=f\"{self.model_type} Training Epochs\", position=0)\n",
        "\n",
        "        for epoch in epoch_progress:\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(self.dataset.data)\n",
        "            loss = self.criterion(output[self.dataset.data.train_mask], self.dataset.data.y[self.dataset.data.train_mask])\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_output = self.model(self.dataset.data)\n",
        "                val_loss = self.criterion(val_output[self.dataset.data.val_mask], self.dataset.data.y[self.dataset.data.val_mask])\n",
        "\n",
        "            history.append({'epoch': epoch, 'loss': loss.item(), 'val_loss': val_loss.item()})\n",
        "            epoch_progress.set_postfix({'Loss': f'{loss.item():.4f}', 'Val Loss': f'{val_loss.item():.4f}'})\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                best_model_state = self.model.state_dict()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    logger.info(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "        self.model.load_state_dict(best_model_state)\n",
        "        history_df = pd.DataFrame(history)\n",
        "        history_df.to_csv(f'training_history_{self.model_type.lower()}.csv', index=False)\n",
        "        logger.info(f\"{self.model_type} Training completed\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        logger.info(f\"Starting {self.model_type} model evaluation\")\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = self.model(self.dataset.data)\n",
        "            val_output = output[self.dataset.data.val_mask].cpu().numpy()\n",
        "            val_y = self.dataset.data.y[self.dataset.data.val_mask].cpu().numpy()\n",
        "\n",
        "            precision, recall, thresholds = precision_recall_curve(val_y, val_output)\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "            optimal_idx = np.argmax(f1_scores)\n",
        "            optimal_threshold = thresholds[optimal_idx]\n",
        "            logger.info(f\"Optimal threshold for {self.model_type}: {optimal_threshold}\")\n",
        "\n",
        "            test_output = output[self.dataset.data.test_mask].cpu().numpy()\n",
        "            test_y = self.dataset.data.y[self.dataset.data.test_mask].cpu().numpy()\n",
        "            test_pred = (test_output > optimal_threshold).astype(int)\n",
        "\n",
        "            logger.info(f\"{self.model_type} Classification Report:\")\n",
        "            report = classification_report(test_y, test_pred, output_dict=True)\n",
        "            print(classification_report(test_y, test_pred))\n",
        "\n",
        "            cm = confusion_matrix(test_y, test_pred)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "            plt.title(f'{self.model_type} Confusion Matrix', fontsize=10)\n",
        "            plt.xlabel('Predicted', fontsize=10)\n",
        "            plt.ylabel('Actual', fontsize=10)\n",
        "            plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'confusion_matrix_{self.model_type.lower()}.png', dpi=config['save_dpi'])\n",
        "            plt.close()\n",
        "            logger.info(f\"{self.model_type} Confusion matrix saved\")\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(test_y, test_output)\n",
        "            roc_auc = roc_auc_score(test_y, test_output)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.plot(fpr, tpr, color='dodgerblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "            plt.plot([0, 1], [0, 1], color='crimson', lw=2, linestyle='--')\n",
        "            plt.xlabel('False Positive Rate', fontsize=10)\n",
        "            plt.ylabel('True Positive Rate', fontsize=10)\n",
        "            plt.title(f'{self.model_type} ROC Curve', fontsize=10)\n",
        "            plt.legend(loc=\"lower right\", fontsize=10)\n",
        "            plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'roc_curve_{self.model_type.lower()}.png', dpi=config['save_dpi'])\n",
        "            plt.close()\n",
        "            logger.info(f\"{self.model_type} ROC curve saved\")\n",
        "\n",
        "            return report, test_output\n",
        "\n",
        "def train_mlp(X_train, y_train, X_val, y_val, epochs=config['epochs'], patience=config['patience']):\n",
        "    logger.info(\"Starting MLP training\")\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = MLP(input_dim)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    criterion = FocalLoss(alpha=0.75, gamma=2)\n",
        "\n",
        "    history = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    epoch_progress = tqdm(range(1, epochs + 1), desc=\"MLP Training Epochs\", position=0)\n",
        "\n",
        "    for epoch in epoch_progress:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train)\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val)\n",
        "            val_loss = criterion(val_output, y_val)\n",
        "\n",
        "        history.append({'epoch': epoch, 'loss': loss.item(), 'val_loss': val_loss.item()})\n",
        "        epoch_progress.set_postfix({'Loss': f'{loss.item():.4f}', 'Val Loss': f'{val_loss.item():.4f}'})\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                logger.info(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_df.to_csv('training_history_mlp.csv', index=False)\n",
        "    logger.info(\"MLP Training completed\")\n",
        "    return model\n",
        "\n",
        "def evaluate_mlp(model, X_val, y_val, X_test, y_test):\n",
        "    logger.info(\"Starting MLP model evaluation\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_output = model(X_val).cpu().numpy()\n",
        "        test_output = model(X_test).cpu().numpy()\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_val.cpu().numpy(), val_output)\n",
        "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    logger.info(f\"Optimal threshold for MLP: {optimal_threshold}\")\n",
        "\n",
        "    test_pred = (test_output > optimal_threshold).astype(int)\n",
        "    logger.info(\"MLP Classification Report:\")\n",
        "    report = classification_report(y_test.cpu().numpy(), test_pred, output_dict=True)\n",
        "    print(classification_report(y_test.cpu().numpy(), test_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test.cpu().numpy(), test_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title('MLP Confusion Matrix', fontsize=10)\n",
        "    plt.xlabel('Predicted', fontsize=10)\n",
        "    plt.ylabel('Actual', fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_mlp.png', dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "    logger.info(\"MLP Confusion matrix saved\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test.cpu().numpy(), test_output)\n",
        "    roc_auc = roc_auc_score(y_test.cpu().numpy(), test_output)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='dodgerblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='crimson', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate', fontsize=10)\n",
        "    plt.ylabel('True Positive Rate', fontsize=10)\n",
        "    plt.title('MLP ROC Curve', fontsize=10)\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curve_mlp.png', dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "    logger.info(\"MLP ROC curve saved\")\n",
        "\n",
        "    return report, test_output\n",
        "\n",
        "def train_iforest(X_train, contamination=0.0022):\n",
        "    logger.info(\"Starting iForest training\")\n",
        "    model = IsolationForest(contamination=contamination, random_state=42)\n",
        "    model.fit(X_train)\n",
        "    logger.info(\"iForest training completed\")\n",
        "    return model\n",
        "\n",
        "def evaluate_iforest(model, X_val, y_val, X_test, y_test):\n",
        "    logger.info(\"Starting iForest model evaluation\")\n",
        "    val_scores = -model.decision_function(X_val)\n",
        "    precision, recall, thresholds = precision_recall_curve(y_val, val_scores)\n",
        "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    logger.info(f\"Optimal threshold for iForest: {optimal_threshold}\")\n",
        "\n",
        "    test_scores = -model.decision_function(X_test)\n",
        "    test_pred = (test_scores > optimal_threshold).astype(int)\n",
        "    logger.info(\"iForest Classification Report:\")\n",
        "    report = classification_report(y_test, test_pred, output_dict=True)\n",
        "    print(classification_report(y_test, test_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, test_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title('iForest Confusion Matrix', fontsize=10)\n",
        "    plt.xlabel('Predicted', fontsize=10)\n",
        "    plt.ylabel('Actual', fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_iforest.png', dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "    logger.info(\"iForest Confusion matrix saved\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, test_scores)\n",
        "    roc_auc = roc_auc_score(y_test, test_scores)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='dodgerblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='crimson', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate', fontsize=10)\n",
        "    plt.ylabel('True Positive Rate', fontsize=10)\n",
        "    plt.title('iForest ROC Curve', fontsize=10)\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('roc_curve_iforest.png', dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "    logger.info(\"iForest ROC curve saved\")\n",
        "\n",
        "    return report, test_scores\n",
        "\n",
        "def plot_training_history(history_path, model_name, save_dpi=config['save_dpi']):\n",
        "    history = pd.read_csv(history_path)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['epoch'], history['loss'], label='Training Loss', color='dodgerblue')\n",
        "    plt.plot(history['epoch'], history['val_loss'], label='Validation Loss', color='crimson')\n",
        "    plt.xlabel('Epoch', fontsize=10)\n",
        "    plt.ylabel('Loss', fontsize=10)\n",
        "    plt.title(f'{model_name} Training and Validation Loss', fontsize=10)\n",
        "    plt.legend(fontsize=10)\n",
        "\n",
        "    final_loss = history['loss'].iloc[-1]\n",
        "    final_val_loss = history['val_loss'].iloc[-1]\n",
        "    plt.annotate(f'Final Train Loss: {final_loss:.4f}', xy=(history['epoch'].iloc[-1], final_loss), xytext=(10, 10), textcoords='offset points', arrowprops=dict(arrowstyle='->'), fontsize=8)\n",
        "    plt.annotate(f'Final Val Loss: {final_val_loss:.4f}', xy=(history['epoch'].iloc[-1], final_val_loss), xytext=(10, -10), textcoords='offset points', arrowprops=dict(arrowstyle='->'), fontsize=8)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_history_{model_name.lower()}.png', dpi=save_dpi)\n",
        "    plt.close()\n",
        "\n",
        "def plot_comparative_curves(y_test, outputs, curve_type='roc'):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['dodgerblue', 'crimson', 'orange', 'green']\n",
        "    for (model_name, test_output), color in zip(outputs.items(), colors):\n",
        "        if curve_type == 'roc':\n",
        "            fpr, tpr, _ = roc_curve(y_test, test_output)\n",
        "            auc = roc_auc_score(y_test, test_output)\n",
        "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', color=color)\n",
        "        else:\n",
        "            precision, recall, _ = precision_recall_curve(y_test, test_output)\n",
        "            plt.plot(recall, precision, label=model_name, color=color)\n",
        "\n",
        "    if curve_type == 'roc':\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlabel('False Positive Rate', fontsize=10)\n",
        "        plt.ylabel('True Positive Rate', fontsize=10)\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curves', fontsize=10)\n",
        "    else:\n",
        "        plt.xlabel('Recall', fontsize=10)\n",
        "        plt.ylabel('Precision', fontsize=10)\n",
        "        plt.title('Precision-Recall Curves', fontsize=10)\n",
        "\n",
        "    plt.legend(loc=\"lower right\" if curve_type == 'roc' else \"lower left\", fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{curve_type}_curves.png', dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    dataset_path = f\"{sakhawat18_asteroid_dataset_path}/dataset.csv\"\n",
        "    dataset = AsteroidGraphDataset(dataset_path)\n",
        "\n",
        "    X = dataset.data.x\n",
        "    y = dataset.data.y\n",
        "    train_mask = dataset.data.train_mask\n",
        "    val_mask = dataset.data.val_mask\n",
        "    test_mask = dataset.data.test_mask\n",
        "\n",
        "    X_train = X[train_mask]\n",
        "    y_train = y[train_mask]\n",
        "    X_val = X[val_mask]\n",
        "    y_val = y[val_mask]\n",
        "    X_test = X[test_mask]\n",
        "    y_test = y[test_mask]\n",
        "\n",
        "    # Train and evaluate GNN\n",
        "    gnn_classifier = AsteroidHazardClassifier(dataset_path, model_type='GNN')\n",
        "    gnn_classifier.train(epochs=config['epochs'], patience=config['patience'])\n",
        "    plot_training_history('training_history_gnn.csv', 'GNN')\n",
        "    gnn_report, gnn_test_output = gnn_classifier.evaluate()\n",
        "\n",
        "    # Train and evaluate MLP\n",
        "    mlp_model = train_mlp(X_train, y_train, X_val, y_val)\n",
        "    plot_training_history('training_history_mlp.csv', 'MLP')\n",
        "    mlp_report, mlp_test_output = evaluate_mlp(mlp_model, X_val, y_val, X_test, y_test)\n",
        "\n",
        "    # Train and evaluate GAT\n",
        "    gat_classifier = AsteroidHazardClassifier(dataset_path, model_type='GAT')\n",
        "    gat_classifier.train(epochs=config['epochs'], patience=config['patience'])\n",
        "    plot_training_history('training_history_gat.csv', 'GAT')\n",
        "    gat_report, gat_test_output = gat_classifier.evaluate()\n",
        "\n",
        "    # Train and evaluate iForest\n",
        "    iforest_model = train_iforest(X_train.cpu().numpy(), contamination=0.0022)\n",
        "    iforest_report, iforest_test_output = evaluate_iforest(iforest_model, X_val.cpu().numpy(), y_val.cpu().numpy(), X_test.cpu().numpy(), y_test.cpu().numpy())\n",
        "\n",
        "    # Compare models\n",
        "    reports = {\n",
        "        'GNN': gnn_report,\n",
        "        'MLP': mlp_report,\n",
        "        'GAT': gat_report,\n",
        "        'iForest': iforest_report\n",
        "    }\n",
        "    outputs = {\n",
        "        'GNN': gnn_test_output,\n",
        "        'MLP': mlp_test_output,\n",
        "        'GAT': gat_test_output,\n",
        "        'iForest': iforest_test_output\n",
        "    }\n",
        "\n",
        "    table = [['Model', 'Precision', 'Recall', 'F1-Score', 'Support']]\n",
        "    for model_name, report in reports.items():\n",
        "        metrics = report['1.0']\n",
        "        table.append([model_name, f\"{metrics['precision']:.2f}\", f\"{metrics['recall']:.2f}\", f\"{metrics['f1-score']:.2f}\", int(metrics['support'])])\n",
        "\n",
        "    logger.info(\"Model Performance Comparison:\")\n",
        "    print(tabulate(table, headers='firstrow', tablefmt='grid'))\n",
        "\n",
        "    # Plot comparative curves\n",
        "    plot_comparative_curves(y_test.cpu().numpy())"
      ],
      "metadata": {
        "id": "x4xw_X8wsCTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MYodrK9ssVDT",
        "outputId": "cab38c78-31e0-44e0-cac3-deb8255cf932"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GNN Training Epochs: 100%|██████████| 100/100 [44:20<00:00, 26.61s/it, Loss=0.0012, Val Loss=0.0012]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    187308\n",
            "         1.0       0.28      0.37      0.32       413\n",
            "\n",
            "    accuracy                           1.00    187721\n",
            "   macro avg       0.64      0.68      0.66    187721\n",
            "weighted avg       1.00      1.00      1.00    187721\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MLP Training Epochs: 100%|██████████| 100/100 [00:40<00:00,  2.47it/s, Loss=0.0015, Val Loss=0.0016]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    187308\n",
            "         1.0       0.20      0.41      0.27       413\n",
            "\n",
            "    accuracy                           1.00    187721\n",
            "   macro avg       0.60      0.71      0.64    187721\n",
            "weighted avg       1.00      1.00      1.00    187721\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GAT Training Epochs: 100%|██████████| 100/100 [29:36<00:00, 17.76s/it, Loss=0.0022, Val Loss=0.0023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00    187308\n",
            "         1.0       0.11      0.17      0.14       413\n",
            "\n",
            "    accuracy                           1.00    187721\n",
            "   macro avg       0.56      0.58      0.57    187721\n",
            "weighted avg       1.00      1.00      1.00    187721\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.97      0.98    187308\n",
            "         1.0       0.04      0.57      0.08       413\n",
            "\n",
            "    accuracy                           0.97    187721\n",
            "   macro avg       0.52      0.77      0.53    187721\n",
            "weighted avg       1.00      0.97      0.98    187721\n",
            "\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| Model   |   Precision |   Recall |   F1-Score |   Support |\n",
            "+=========+=============+==========+============+===========+\n",
            "| GNN     |        0.28 |     0.37 |       0.32 |       413 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| MLP     |        0.2  |     0.41 |       0.27 |       413 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| GAT     |        0.11 |     0.17 |       0.14 |       413 |\n",
            "+---------+-------------+----------+------------+-----------+\n",
            "| iForest |        0.04 |     0.57 |       0.08 |       413 |\n",
            "+---------+-------------+----------+------------+-----------+\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "plot_comparative_curves() missing 1 required positional argument: 'outputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-44e33c51c812>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;31m# Plot comparative curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mplot_comparative_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: plot_comparative_curves() missing 1 required positional argument: 'outputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn -q"
      ],
      "metadata": {
        "id": "B6sNu_tiOWBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from tabulate import tabulate\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "import os\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'epochs': 100,\n",
        "    'patience': 10,\n",
        "    'save_dpi': 300,\n",
        "    'display_dpi': 120\n",
        "}\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets, weights=None):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "        F_loss = alpha_t * (1 - pt) ** self.gamma * BCE_loss\n",
        "        if weights is not None:\n",
        "            F_loss = F_loss * weights\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "class AsteroidGraphDataset:\n",
        "    def __init__(self, filepath):\n",
        "        logger.info(f\"Loading dataset from {filepath}\")\n",
        "        self.df = pd.read_csv(filepath, low_memory=False)\n",
        "        self.df = self.df.dropna(subset=['pha'])\n",
        "        logger.info(f\"After dropping rows with missing 'pha', dataset size: {len(self.df)}\")\n",
        "\n",
        "        features = ['e', 'a', 'i', 'q', 'tp', 'H', 'diameter', 'albedo', 'moid_ld']\n",
        "        X = self.df[features].astype(float).values\n",
        "        y = (self.df['pha'] == 'Y').astype(int).values\n",
        "\n",
        "        indices = np.arange(len(self.df))\n",
        "        train_val_indices, test_indices = train_test_split(\n",
        "            indices, test_size=0.2, stratify=y, random_state=42\n",
        "        )\n",
        "        train_indices, val_indices = train_test_split(\n",
        "            train_val_indices, test_size=0.2, stratify=y[train_val_indices], random_state=42\n",
        "        )\n",
        "\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        imputer.fit(X[train_indices])\n",
        "        X_imputed = imputer.transform(X)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_imputed[train_indices])\n",
        "        X_scaled = scaler.transform(X_imputed)\n",
        "\n",
        "        train_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        val_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        test_mask = torch.zeros(len(self.df), dtype=torch.bool)\n",
        "        train_mask[train_indices] = True\n",
        "        val_mask[val_indices] = True\n",
        "        test_mask[test_indices] = True\n",
        "\n",
        "        connectivity = kneighbors_graph(X_scaled, n_neighbors=5, mode='connectivity')\n",
        "        rows, cols = connectivity.nonzero()\n",
        "        edge_index_np = np.vstack((rows, cols))\n",
        "        edge_index = torch.from_numpy(edge_index_np).to(torch.long)\n",
        "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
        "\n",
        "        self.data = Data(x=torch.tensor(X_scaled, dtype=torch.float),\n",
        "                         edge_index=edge_index,\n",
        "                         y=torch.tensor(y, dtype=torch.float),\n",
        "                         train_mask=train_mask,\n",
        "                         val_mask=val_mask,\n",
        "                         test_mask=test_mask)\n",
        "\n",
        "        logger.info(f\"Graph constructed with {self.data.num_nodes} nodes and {self.data.num_edges} edges\")\n",
        "\n",
        "class AsteroidGNN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(AsteroidGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 128)\n",
        "        self.conv2 = GCNConv(128, 128)\n",
        "        self.conv3 = GCNConv(128, 128)\n",
        "        self.attn = GATConv(128, 64, heads=2)\n",
        "        self.fc = nn.Linear(64 * 2, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = F.relu(self.attn(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "def augment_with_smote(data, sampling_strategy=0.1, k_neighbors=5):\n",
        "    X_train = data.x[data.train_mask].cpu().numpy()\n",
        "    y_train = data.y[data.train_mask].cpu().numpy()\n",
        "    smote = SMOTE(sampling_strategy=sampling_strategy, k_neighbors=k_neighbors, random_state=42)\n",
        "    X_synthetic, y_synthetic = smote.fit_resample(X_train, y_train)\n",
        "    X_synthetic = X_synthetic[len(X_train):]\n",
        "    y_synthetic = y_synthetic[len(y_train):]\n",
        "    X_synthetic = torch.tensor(X_synthetic, dtype=torch.float)\n",
        "    y_synthetic = torch.tensor(y_synthetic, dtype=torch.float)\n",
        "    num_synthetic = X_synthetic.shape[0]\n",
        "    original_num_nodes = data.x.shape[0]\n",
        "    data.x = torch.cat([data.x, X_synthetic], dim=0)\n",
        "    data.y = torch.cat([data.y, y_synthetic], dim=0)\n",
        "    data.train_mask = torch.cat([data.train_mask, torch.ones(num_synthetic, dtype=torch.bool)], dim=0)\n",
        "    data.val_mask = torch.cat([data.val_mask, torch.zeros(num_synthetic, dtype=torch.bool)], dim=0)\n",
        "    data.test_mask = torch.cat([data.test_mask, torch.zeros(num_synthetic, dtype=torch.bool)], dim=0)\n",
        "    nn = NearestNeighbors(n_neighbors=k_neighbors)\n",
        "    nn.fit(data.x[:original_num_nodes].cpu().numpy())\n",
        "    distances, indices = nn.kneighbors(X_synthetic.cpu().numpy())\n",
        "    edge_list = []\n",
        "    for i, orig_indices in enumerate(indices):\n",
        "        syn_idx = original_num_nodes + i\n",
        "        for orig_idx in orig_indices:\n",
        "            edge_list.append([syn_idx, orig_idx])\n",
        "            edge_list.append([orig_idx, syn_idx])\n",
        "    edge_list = np.array(edge_list).T\n",
        "    edge_list = torch.tensor(edge_list, dtype=torch.long)\n",
        "    data.edge_index = torch.cat([data.edge_index, edge_list], dim=1)\n",
        "    return data\n",
        "\n",
        "class AsteroidHazardClassifier:\n",
        "    def __init__(self, dataset_path, imbalance_method='original', smote_strategy=0.1, focal_alpha=0.75, focal_gamma=2, models_dir='/content/output/models', output_dir='/content/output', plots_dir='/content/output/plots'):\n",
        "        logger.info(f\"Initializing GNN Classifier with imbalance method {imbalance_method}\")\n",
        "        self.dataset = AsteroidGraphDataset(dataset_path)\n",
        "        self.imbalance_method = imbalance_method\n",
        "        self.smote_strategy = smote_strategy\n",
        "        self.models_dir = models_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.plots_dir = plots_dir\n",
        "        num_features = len(['e', 'a', 'i', 'q', 'tp', 'H', 'diameter', 'albedo', 'moid_ld'])\n",
        "        self.model = AsteroidGNN(num_features)\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "        self.criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
        "\n",
        "        if imbalance_method == 'smote':\n",
        "            self.data = augment_with_smote(self.dataset.data.clone(), sampling_strategy=smote_strategy)\n",
        "        else:\n",
        "            self.data = self.dataset.data\n",
        "\n",
        "        if imbalance_method == 'weighted':\n",
        "            y_train = self.data.y[self.data.train_mask]\n",
        "            num_pos = (y_train == 1).sum().item()\n",
        "            num_neg = (y_train == 0).sum().item()\n",
        "            total = len(y_train)\n",
        "            self.class_weight = {\n",
        "                0: total / (2 * num_neg),\n",
        "                1: total / (2 * num_pos)\n",
        "            }\n",
        "        else:\n",
        "            self.class_weight = None\n",
        "\n",
        "    def train(self, epochs=config['epochs'], patience=config['patience']):\n",
        "        logger.info(f\"Starting GNN training for {epochs} epochs\")\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "        best_model_state = None\n",
        "        history = []\n",
        "\n",
        "        epoch_progress = tqdm(range(1, epochs + 1), desc=f\"GNN {self.imbalance_method} Training Epochs\", position=0)\n",
        "\n",
        "        for epoch in epoch_progress:\n",
        "            self.model.train()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(self.data)\n",
        "            if self.imbalance_method == 'weighted':\n",
        "                weights = torch.tensor([self.class_weight[int(y)] for y in self.data.y[self.data.train_mask]], device=self.data.x.device)\n",
        "                loss = self.criterion(output[self.data.train_mask], self.data.y[self.data.train_mask], weights=weights)\n",
        "            else:\n",
        "                loss = self.criterion(output[self.data.train_mask], self.data.y[self.data.train_mask])\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_output = self.model(self.data)\n",
        "                logger.info(f\"val_output shape: {val_output.shape}, val_mask shape: {self.data.val_mask.shape}\")\n",
        "                val_loss = self.criterion(val_output[self.data.val_mask], self.data.y[self.data.val_mask])\n",
        "\n",
        "            history.append({'epoch': epoch, 'loss': loss.item(), 'val_loss': val_loss.item()})\n",
        "            epoch_progress.set_postfix({'Loss': f'{loss.item():.4f}', 'Val Loss': f'{val_loss.item():.4f}'})\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                best_model_state = self.model.state_dict()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    logger.info(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "        self.model.load_state_dict(best_model_state)\n",
        "        torch.save(best_model_state, os.path.join(self.models_dir, f'gnn_{self.imbalance_method}.pth'))\n",
        "        history_df = pd.DataFrame(history)\n",
        "        history_df.to_csv(os.path.join(self.output_dir, f'training_history_gnn_{self.imbalance_method}.csv'), index=False)\n",
        "        logger.info(f\"GNN Training completed\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        logger.info(f\"Starting GNN model evaluation\")\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = self.model(self.data)\n",
        "            val_output = output[self.data.val_mask].cpu().numpy()\n",
        "            val_y = self.data.y[self.data.val_mask].cpu().numpy()\n",
        "\n",
        "            precision, recall, thresholds = precision_recall_curve(val_y, val_output)\n",
        "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "            optimal_idx = np.argmax(f1_scores)\n",
        "            optimal_threshold = thresholds[optimal_idx]\n",
        "            logger.info(f\"Optimal threshold for GNN: {optimal_threshold}\")\n",
        "\n",
        "            test_output = output[self.data.test_mask].cpu().numpy()\n",
        "            test_y = self.data.y[self.data.test_mask].cpu().numpy()\n",
        "            test_pred = (test_output > optimal_threshold).astype(int)\n",
        "\n",
        "            logger.info(f\"GNN Classification Report:\")\n",
        "            report = classification_report(test_y, test_pred, output_dict=True)\n",
        "            print(classification_report(test_y, test_pred))\n",
        "\n",
        "            cm = confusion_matrix(test_y, test_pred)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "            plt.title(f'GNN {self.imbalance_method} Confusion Matrix', fontsize=10)\n",
        "            plt.xlabel('Predicted', fontsize=10)\n",
        "            plt.ylabel('Actual', fontsize=10)\n",
        "            plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(self.plots_dir, f'confusion_matrix_gnn_{self.imbalance_method}.png'), dpi=config['save_dpi'])\n",
        "            plt.close()\n",
        "            logger.info(f\"GNN Confusion matrix saved\")\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(test_y, test_output)\n",
        "            roc_auc = roc_auc_score(test_y, test_output)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.plot(fpr, tpr, color='dodgerblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "            plt.plot([0, 1], [0, 1], color='crimson', lw=2, linestyle='--')\n",
        "            plt.xlabel('False Positive Rate', fontsize=10)\n",
        "            plt.ylabel('True Positive Rate', fontsize=10)\n",
        "            plt.title(f'GNN {self.imbalance_method} ROC Curve', fontsize=10)\n",
        "            plt.legend(loc=\"lower right\", fontsize=10)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(self.plots_dir, f'roc_curve_gnn_{self.imbalance_method}.png'), dpi=config['save_dpi'])\n",
        "            plt.close()\n",
        "            logger.info(f\"GNN ROC curve saved\")\n",
        "\n",
        "            return report, test_output\n",
        "\n",
        "def plot_training_history(history_path, model_name, save_dpi=config['save_dpi'], plots_dir='/content/output/plots'):\n",
        "    history = pd.read_csv(history_path)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['epoch'], history['loss'], label='Training Loss', color='dodgerblue')\n",
        "    plt.plot(history['epoch'], history['val_loss'], label='Validation Loss', color='crimson')\n",
        "    plt.xlabel('Epoch', fontsize=10)\n",
        "    plt.ylabel('Loss', fontsize=10)\n",
        "    plt.title(f'{model_name} Training and Validation Loss', fontsize=10)\n",
        "    plt.legend(fontsize=10)\n",
        "\n",
        "    final_loss = history['loss'].iloc[-1]\n",
        "    final_val_loss = history['val_loss'].iloc[-1]\n",
        "    plt.annotate(f'Final Train Loss: {final_loss:.4f}', xy=(history['epoch'].iloc[-1], final_loss), xytext=(10, 10), textcoords='offset points', arrowprops=dict(arrowstyle='->'), fontsize=8)\n",
        "    plt.annotate(f'Final Val Loss: {final_val_loss:.4f}', xy=(history['epoch'].iloc[-1], final_val_loss), xytext=(10, -10), textcoords='offset points', arrowprops=dict(arrowstyle='->'), fontsize=8)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, f'training_history_{model_name.lower().replace(\" \", \"_\")}.png'), dpi=save_dpi)\n",
        "    plt.close()\n",
        "\n",
        "def plot_comparative_curves(y_test, outputs, curve_type='roc', plots_dir='/content/output/plots'):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['dodgerblue', 'crimson', 'orange']\n",
        "    for (model_name, test_output), color in zip(outputs.items(), colors):\n",
        "        if curve_type == 'roc':\n",
        "            fpr, tpr, _ = roc_curve(y_test, test_output)\n",
        "            auc = roc_auc_score(y_test, test_output)\n",
        "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.2f})', color=color)\n",
        "        elif curve_type == 'pr':\n",
        "            precision, recall, _ = precision_recall_curve(y_test, test_output)\n",
        "            plt.plot(recall, precision, label=model_name, color=color)\n",
        "\n",
        "    if curve_type == 'roc':\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlabel('False Positive Rate', fontsize=10)\n",
        "        plt.ylabel('True Positive Rate', fontsize=10)\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curves', fontsize=10)\n",
        "    else:\n",
        "        plt.xlabel('Recall', fontsize=10)\n",
        "        plt.ylabel('Precision', fontsize=10)\n",
        "        plt.title('Precision-Recall Curves', fontsize=10)\n",
        "\n",
        "    plt.legend(loc=\"lower right\" if curve_type == 'roc' else \"lower left\", fontsize=10)\n",
        "    plt.text(0.5, -0.1, 'Data Source: NASA JPL Small-Body Database', ha='center', va='center', transform=plt.gca().transAxes, fontsize=8)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(plots_dir, f'{curve_type}_curves.png'), dpi=config['save_dpi'])\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    output_dir = '/content/output'\n",
        "    models_dir = os.path.join(output_dir, 'models')\n",
        "    plots_dir = os.path.join(output_dir, 'plots')\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    dataset_path = f\"{sakhawat18_asteroid_dataset_path}/dataset.csv\"\n",
        "    dataset = AsteroidGraphDataset(dataset_path)\n",
        "\n",
        "    # Train SMOTE GNN\n",
        "    gnn_smote = AsteroidHazardClassifier(dataset_path, imbalance_method='smote', smote_strategy=0.1, models_dir=models_dir, output_dir=output_dir, plots_dir=plots_dir)\n",
        "    gnn_smote.train()\n",
        "    plot_training_history(os.path.join(output_dir, 'training_history_gnn_smote.csv'), 'GNN SMOTE', plots_dir=plots_dir)\n",
        "    gnn_smote_report, gnn_smote_test_output = gnn_smote.evaluate()\n",
        "\n",
        "    # Train adjusted Focal Loss GNN\n",
        "    gnn_adjusted_focal = AsteroidHazardClassifier(dataset_path, imbalance_method='original', focal_alpha=0.9, focal_gamma=3, models_dir=models_dir, output_dir=output_dir, plots_dir=plots_dir)\n",
        "    gnn_adjusted_focal.train()\n",
        "    plot_training_history(os.path.join(output_dir, 'training_history_gnn_adjusted_focal.csv'), 'GNN Adjusted Focal', plots_dir=plots_dir)\n",
        "    gnn_adjusted_focal_report, gnn_adjusted_focal_test_output = gnn_adjusted_focal.evaluate()\n",
        "\n",
        "    # Train weighted GNN\n",
        "    gnn_weighted = AsteroidHazardClassifier(dataset_path, imbalance_method='weighted', models_dir=models_dir, output_dir=output_dir, plots_dir=plots_dir)\n",
        "    gnn_weighted.train()\n",
        "    plot_training_history(os.path.join(output_dir, 'training_history_gnn_weighted.csv'), 'GNN Weighted', plots_dir=plots_dir)\n",
        "    gnn_weighted_report, gnn_weighted_test_output = gnn_weighted.evaluate()\n",
        "\n",
        "    # Collect reports and outputs\n",
        "    reports = {\n",
        "        'GNN SMOTE': gnn_smote_report,\n",
        "        'GNN Adjusted Focal': gnn_adjusted_focal_report,\n",
        "        'GNN Weighted': gnn_weighted_report\n",
        "    }\n",
        "    outputs = {\n",
        "        'GNN SMOTE': gnn_smote_test_output,\n",
        "        'GNN Adjusted Focal': gnn_adjusted_focal_test_output,\n",
        "        'GNN Weighted': gnn_weighted_test_output\n",
        "    }\n",
        "\n",
        "    # Print comparison table\n",
        "    data = []\n",
        "    for model_name, report in reports.items():\n",
        "        metrics = report['1.0']\n",
        "        data.append([model_name, metrics['precision'], metrics['recall'], metrics['f1-score'], metrics['support']])\n",
        "    df = pd.DataFrame(data, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'Support'])\n",
        "    logger.info(\"Model Performance Comparison:\")\n",
        "    print(df)\n",
        "\n",
        "    # Plot comparative curves\n",
        "    y_test = dataset.data.y[dataset.data.test_mask].cpu().numpy()\n",
        "    plot_comparative_curves(y_test, outputs, curve_type='roc', plots_dir=plots_dir)\n",
        "    plot_comparative_curves(y_test, outputs, curve_type='pr', plots_dir=plots_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "uBBycr9QOTed",
        "outputId": "345f3564-2cea-4363-b87b-6b648fcbf25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GNN smote Training Epochs: 100%|██████████| 100/100 [48:38<00:00, 29.19s/it, Loss=0.0011, Val Loss=0.0010]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      1.00    187308\n",
            "         1.0       0.24      0.78      0.37       413\n",
            "\n",
            "    accuracy                           0.99    187721\n",
            "   macro avg       0.62      0.89      0.68    187721\n",
            "weighted avg       1.00      0.99      1.00    187721\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GNN original Training Epochs: 100%|██████████| 100/100 [45:47<00:00, 27.48s/it, Loss=0.0003, Val Loss=0.0003]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/output/training_history_gnn_adjusted_focal.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-70f25c3766d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-70f25c3766d5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mgnn_adjusted_focal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAsteroidHazardClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimbalance_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocal_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocal_gamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplots_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mgnn_adjusted_focal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mplot_training_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_history_gnn_adjusted_focal.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GNN Adjusted Focal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplots_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mgnn_adjusted_focal_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgnn_adjusted_focal_test_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_adjusted_focal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-70f25c3766d5>\u001b[0m in \u001b[0;36mplot_training_history\u001b[0;34m(history_path, model_name, save_dpi, plots_dir)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_training_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_dpi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplots_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/output/plots'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dodgerblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/output/training_history_gnn_adjusted_focal.csv'"
          ]
        }
      ]
    }
  ]
}